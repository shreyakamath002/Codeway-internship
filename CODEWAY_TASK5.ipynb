{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d48a4523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from os import walk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage.measure import find_contours\n",
    "from skimage.morphology import binary_dilation\n",
    "from sklearn.svm import SVC\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import TensorDataset\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0876f01a",
   "metadata": {},
   "source": [
    "#####  Parameters and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4d73d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "AVAILABLE_WRITERS = 672\n",
    "RESULTS_FILE = 'results.txt'\n",
    "TIME_FILE = 'time.txt'\n",
    "OVERLAPPING_METHOD = 0\n",
    "LINES_METHOD = 1\n",
    "SUPPORT_VECTOR_CLASSIFIER = 0\n",
    "NEURAL_NETWORK_CLASSIFIER = 1\n",
    "HISTOGRAM_BINS = 256\n",
    "NN_LEARNING_RATE = 0.003\n",
    "NN_WEIGHT_DECAY = 0.01\n",
    "NN_DROPOUT = 0.25\n",
    "NN_EPOCHS = 200\n",
    "NN_BATCH_SIZE = 16\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a26b2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, titles=None):\n",
    "    n_ims = len(images)\n",
    "    if titles is None:\n",
    "        titles = ['(%d)' % i for i in range(1, n_ims + 1)]\n",
    "    fig = plt.figure()\n",
    "    n = 1\n",
    "    for image, title in zip(images, titles):\n",
    "        a = fig.add_subplot(1, n_ims, n)\n",
    "        if image.ndim == 2:\n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "        n += 1\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_ims)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2adddd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img, feature_extraction_method=OVERLAPPING_METHOD):\n",
    "    if feature_extraction_method == OVERLAPPING_METHOD:\n",
    "        img_copy = img.copy()\n",
    "        if len(img.shape) > 2:\n",
    "            img_copy = cv2.cvtColor(img_copy, cv2.COLOR_BGR2GRAY)\n",
    "        img_copy = cv2.medianBlur(img_copy, 5)\n",
    "        img_copy = cv2.threshold(img_copy, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "        min_vertical, max_vertical = get_corpus_boundaries(img_copy)\n",
    "        img_copy = img_copy[min_vertical:max_vertical]\n",
    "        return img_copy\n",
    "\n",
    "    if feature_extraction_method == LINES_METHOD:\n",
    "        img_copy = img.copy()\n",
    "        if len(img.shape) > 2:\n",
    "            grayscale_img = cv2.cvtColor(img_copy, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            grayscale_img = img.copy()\n",
    "        img_copy = cv2.threshold(grayscale_img, 127, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "        min_vertical, max_vertical = get_corpus_boundaries(img_copy)\n",
    "        img_copy = img_copy[min_vertical:max_vertical]\n",
    "        grayscale_img = grayscale_img[min_vertical:max_vertical]\n",
    "        filter_kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])\n",
    "        img_copy_sharpened = cv2.filter2D(img_copy, -1, filter_kernel)\n",
    "        return img_copy_sharpened, grayscale_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a31d374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus_boundaries(img):\n",
    "    crop = []\n",
    "    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (100, 1))\n",
    "    detect_horizontal = cv2.morphologyEx(img, cv2.MORPH_OPEN, horizontal_kernel, iterations=2)\n",
    "    contours = cv2.findContours(detect_horizontal, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = contours[0] if len(contours) == 2 else contours[1]\n",
    "    prev = -1\n",
    "    for i, c in enumerate(contours):\n",
    "        if np.abs(prev - int(c[0][0][1])) > 800 or prev == -1:\n",
    "            crop.append(int(c[0][0][1]))\n",
    "            prev = int(c[0][0][1])\n",
    "    crop.sort()\n",
    "    max_vertical = crop[1] - 20\n",
    "    min_vertical = crop[0] + 20\n",
    "    return min_vertical, max_vertical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5f9bcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_image(img, num, grayscale_img=None):\n",
    "    if grayscale_img is not None:\n",
    "        grayscale_images = []\n",
    "        img_copy = np.copy(img)\n",
    "        kernel = np.ones((1, num))\n",
    "        img_copy = binary_dilation(img_copy, kernel)\n",
    "        bounding_boxes = find_contours(img_copy, 0.8)\n",
    "        for box in bounding_boxes:\n",
    "            x_min = int(np.min(box[:, 1]))\n",
    "            x_max = int(np.max(box[:, 1]))\n",
    "            y_min = int(np.min(box[:, 0]))\n",
    "            y_max = int(np.max(box[:, 0]))\n",
    "            if (y_max - y_min) > 50 and (x_max - x_min) > 50:\n",
    "                grayscale_images.append(grayscale_img[y_min:y_max, x_min:x_max])\n",
    "        return grayscale_images\n",
    "    images = []\n",
    "    img_copy = np.copy(img)\n",
    "    kernel = np.ones((1, num))\n",
    "    img_copy = binary_dilation(img_copy, kernel)\n",
    "    bounding_boxes = find_contours(img_copy, 0.8)\n",
    "    for box in bounding_boxes:\n",
    "        x_min = int(np.min(box[:, 1]))\n",
    "        x_max = int(np.max(box[:, 1]))\n",
    "        y_min = int(np.min(box[:, 0]))\n",
    "        y_max = int(np.max(box[:, 0]))\n",
    "        if (y_max - y_min) > 10 and (x_max - x_min) > 10:\n",
    "            images.append(img[y_min:y_max, x_min:x_max])\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2964b5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_words(words, avg_height):\n",
    "    overlapped_img = np.zeros((3600, 320))\n",
    "    index_i = 0\n",
    "    index_j = 0\n",
    "    max_height = 0\n",
    "    for word in words:\n",
    "        if word.shape[1] + index_j > overlapped_img.shape[1]:\n",
    "            max_height = 0\n",
    "            index_j = 0\n",
    "            index_i += int(avg_height // 2)\n",
    "        if word.shape[1] < overlapped_img.shape[1] and word.shape[0] < overlapped_img.shape[0]:\n",
    "            indices = np.copy(overlapped_img[index_i:index_i + word.shape[0], index_j:index_j + word.shape[1]])\n",
    "            indices = np.maximum(indices, word)\n",
    "            overlapped_img[index_i:index_i + word.shape[0], index_j:index_j + word.shape[1]] = indices\n",
    "            index_j += word.shape[1]\n",
    "            if max_height < word.shape[0]:\n",
    "                max_height = word.shape[0]\n",
    "    overlapped_img = overlapped_img[:index_i + int(avg_height // 2), :]\n",
    "    return overlapped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09b55fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_textures(image):\n",
    "    index_i = 0\n",
    "    index_j = 0\n",
    "    texture_size = 100\n",
    "    textures = []\n",
    "    while index_i + texture_size < image.shape[0]:\n",
    "        if index_j + texture_size > image.shape[1]:\n",
    "            index_j = 0\n",
    "            index_i += texture_size\n",
    "        textures.append(np.copy(image[index_i: index_i + texture_size, index_j: index_j + texture_size]))\n",
    "        index_j += texture_size\n",
    "    return textures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cc53b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_generator(features, labels, feature_extraction_method=OVERLAPPING_METHOD,\n",
    "                    classifier_type=SUPPORT_VECTOR_CLASSIFIER):\n",
    "    histograms = []\n",
    "\n",
    "    if feature_extraction_method == OVERLAPPING_METHOD:\n",
    "        for texture_array in features:\n",
    "            for texture in texture_array:\n",
    "                lbp = local_binary_pattern(texture, 8, 3, 'default')\n",
    "                histogram, _ = np.histogram(lbp, density=False, bins=HISTOGRAM_BINS, range=(0, HISTOGRAM_BINS))\n",
    "                histograms.append(histogram)\n",
    "\n",
    "    elif feature_extraction_method == LINES_METHOD:\n",
    "        for line in features:\n",
    "            lbp = local_binary_pattern(line, 8, 3, 'default')\n",
    "            histogram, _ = np.histogram(lbp, density=False, bins=HISTOGRAM_BINS, range=(0, HISTOGRAM_BINS))\n",
    "            histograms.append(histogram)\n",
    "\n",
    "    if classifier_type == SUPPORT_VECTOR_CLASSIFIER:\n",
    "        model = SVC(kernel='linear')\n",
    "        model.fit(histograms, labels)\n",
    "        return model\n",
    "\n",
    "    if classifier_type == NEURAL_NETWORK_CLASSIFIER:\n",
    "        model = nn.Sequential(nn.Linear(HISTOGRAM_BINS, 128),\n",
    "                              nn.ReLU(),\n",
    "                              nn.Dropout(p=NN_DROPOUT),\n",
    "                              nn.Linear(128, 64),\n",
    "                              nn.ReLU(),\n",
    "                              nn.Dropout(p=NN_DROPOUT),\n",
    "                              nn.Linear(64, 3))\n",
    "        model.to(DEVICE)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adamax(model.parameters(), lr=NN_LEARNING_RATE, weight_decay=NN_WEIGHT_DECAY)\n",
    "        inputs = torch.Tensor(histograms)\n",
    "        labels = torch.tensor(labels, dtype=torch.long) - 1\n",
    "        dataset = TensorDataset(inputs, labels)\n",
    "        train_loader = torch.utils.data.DataLoader(dataset, batch_size=NN_BATCH_SIZE, shuffle=True)\n",
    "        for epoch in range(NN_EPOCHS):\n",
    "            for inputs, labels in train_loader:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                output = model(inputs)\n",
    "                loss = criterion(output, labels)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e438e00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_image, feature_extraction_method=OVERLAPPING_METHOD, classifier_type=SUPPORT_VECTOR_CLASSIFIER):\n",
    "    if feature_extraction_method == OVERLAPPING_METHOD:\n",
    "        img = preprocess_image(test_image)\n",
    "        words = segment_image(img, 3)\n",
    "        avg_height = 0\n",
    "        for word in words:\n",
    "            avg_height += word.shape[0] / len(words)\n",
    "        overlapped_img = overlap_words(words, avg_height)\n",
    "        textures = get_textures(overlapped_img)\n",
    "        prediction = np.zeros(4)\n",
    "        for texture in textures:\n",
    "            lbp = local_binary_pattern(texture, 8, 3, 'default')\n",
    "            histogram, _ = np.histogram(lbp, density=False, bins=HISTOGRAM_BINS, range=(0, HISTOGRAM_BINS))\n",
    "            if classifier_type == SUPPORT_VECTOR_CLASSIFIER:\n",
    "                prediction[model.predict([histogram])] += 1\n",
    "            if classifier_type == NEURAL_NETWORK_CLASSIFIER:\n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "                    histogram = torch.Tensor(histogram)\n",
    "                    probabilities = F.softmax(model.forward(histogram), dim=0)\n",
    "                    _, top_class = probabilities.topk(1)\n",
    "                    prediction[top_class + 1] += 1\n",
    "        return np.argmax(prediction)\n",
    "\n",
    "    if feature_extraction_method == LINES_METHOD:\n",
    "        img, grayscale_img = preprocess_image(test_image, feature_extraction_method)\n",
    "        grayscale_lines = segment_image(img, 100, grayscale_img)\n",
    "        prediction = np.zeros(4)\n",
    "        for line in grayscale_lines:\n",
    "            lbp = local_binary_pattern(line, 8, 3, 'default')\n",
    "            histogram, _ = np.histogram(lbp, density=False, bins=HISTOGRAM_BINS, range=(0, HISTOGRAM_BINS))\n",
    "            if classifier_type == SUPPORT_VECTOR_CLASSIFIER:\n",
    "                prediction[model.predict([histogram])] += 1\n",
    "            if classifier_type == NEURAL_NETWORK_CLASSIFIER:\n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "                    histogram = torch.Tensor(histogram)\n",
    "                    probabilities = F.softmax(model.forward(histogram), dim=0)\n",
    "                    _, top_class = probabilities.topk(1)\n",
    "                    prediction[top_class + 1] += 1\n",
    "        return np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d1e035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_random_images(root):\n",
    "    images = []\n",
    "    labels = []\n",
    "    test_images = []\n",
    "    test_labels = []\n",
    "    for i in range(3):\n",
    "        found_images = False\n",
    "        while not found_images:\n",
    "            images_path = root\n",
    "            random_writer = random.randrange(AVAILABLE_WRITERS)\n",
    "            if random_writer < 10:\n",
    "                random_writer = \"00\" + str(random_writer)\n",
    "            elif random_writer < 100:\n",
    "                random_writer = \"0\" + str(random_writer)\n",
    "            images_path = os.path.join(images_path, str(random_writer))\n",
    "            if not os.path.isdir(images_path):\n",
    "                continue\n",
    "            _, _, filenames = next(walk(images_path))\n",
    "            if len(filenames) <= 2 and i == 2 and len(test_images) == 0:\n",
    "                continue\n",
    "            if len(filenames) >= 2:\n",
    "                found_images = True\n",
    "                chosen_filenames = []\n",
    "                for j in range(2):\n",
    "                    random_filename = random.choice(filenames)\n",
    "                    while random_filename in chosen_filenames:\n",
    "                        random_filename = random.choice(filenames)\n",
    "                    chosen_filenames.append(random_filename)\n",
    "                    images.append(cv2.imread(os.path.join(images_path, random_filename)))\n",
    "                    labels.append(i + 1)\n",
    "                if len(filenames) >= 3:\n",
    "                    random_filename = random.choice(filenames)\n",
    "                    while random_filename in chosen_filenames:\n",
    "                        random_filename = random.choice(filenames)\n",
    "                    chosen_filenames.append(random_filename)\n",
    "                    test_images.append(cv2.imread(os.path.join(images_path, random_filename)))\n",
    "                    test_labels.append(i + 1)\n",
    "    test_choice = random.randint(0, len(test_images) - 1)\n",
    "    test_image = test_images[test_choice]\n",
    "    test_label = test_labels[test_choice]\n",
    "    return images, labels, test_image, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fe45cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images, labels, feature_extraction_method=OVERLAPPING_METHOD):\n",
    "    if feature_extraction_method == LINES_METHOD:\n",
    "        lines_labels = []\n",
    "        lines = []\n",
    "        for image, label in zip(images, labels):\n",
    "            image, grayscale_image = preprocess_image(image, feature_extraction_method)\n",
    "            grayscale_lines = segment_image(image, 100, grayscale_image)\n",
    "            for line in grayscale_lines:\n",
    "                lines.append(line)\n",
    "                lines_labels.append(label)\n",
    "        return lines, lines_labels\n",
    "\n",
    "    if feature_extraction_method == OVERLAPPING_METHOD:\n",
    "        textures = []\n",
    "        textures_labels = []\n",
    "        for image, label in zip(images, labels):\n",
    "            image = preprocess_image(image)\n",
    "            words = segment_image(image, 3)\n",
    "            avg_height = 0\n",
    "            for word in words:\n",
    "                avg_height += word.shape[0] / len(words)\n",
    "            overlapped_img = overlap_words(words, avg_height)\n",
    "            new_textures = get_textures(overlapped_img)\n",
    "            textures.append(new_textures)\n",
    "            for j in range(len(new_textures)):\n",
    "                textures_labels.append(label)\n",
    "        return textures, textures_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad75949",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "root='../input/iam-handwritten-forms-dataset/data'\n",
    "feature_extraction_method=OVERLAPPING_METHOD\n",
    "classifier_type=SUPPORT_VECTOR_CLASSIFIER\n",
    "correct_predictions = 0\n",
    "total_execution_time = 0\n",
    "for epoch in range(epochs):\n",
    "    images, labels, test_image, test_label = read_random_images(root)\n",
    "    start_time = time.time()\n",
    "    features, features_labels = extract_features(images, labels, feature_extraction_method)\n",
    "    model = model_generator(features, features_labels, feature_extraction_method, classifier_type)\n",
    "    prediction = predict(model, test_image, feature_extraction_method, classifier_type)\n",
    "    execution_time = time.time() - start_time\n",
    "    total_execution_time += execution_time\n",
    "    if prediction == test_label:\n",
    "        correct_predictions += 1\n",
    "    print(\"Epoch #{} | Execution time {} seconds | Model accuracy {}\".format(epoch + 1, round(execution_time, 2), round((correct_predictions / (epoch + 1)) * 100, 2)))\n",
    "print(\"Model accuracy = {}% using {} sample tests.\".format((correct_predictions / epochs) * 100, epochs))\n",
    "print(\"Total execution time = {} using {} sample tests.\".format(round(total_execution_time, 2), epochs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
